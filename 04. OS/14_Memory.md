# 메모리

## 주기억 장치**(main memory)**

- 메인 메모리: CPU가 직접 접근할 수 있는 기억 장치. 프로세스가 실행되려면 프로그램이 메모리에 올라와야 함
- CPU는 레지스터가 지시하는대로 메모리에 접근해 다음에 수행할 명령어를 가져옴
- 명령어 수행 시 필요한 데이터가 메모리에 없으면 해당 데이터를 CPU 접근 전에 메모리로 우선 가져와야 함 - MMU(메모리 관리장치)가 함.

---

## **MMU의 메모리 보호**

- 메모리 관리장치(MMU):
    - CPU가 메모리에 접근하는 것을 총 관리해주는 하드웨어
        - 캐시 관리
            - 메인 메모리로의 직접 접근은 비효율적 → CPU와 메인 메모리 속도를 맞추기 위해 캐시가 존재
        - 메모리 보호
            - 프로세스는 독립적인 메모리 공간을 가져야 되고, 자신의 공간만 접근해야 함
                
                → 한 프로세스에게 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 trap을 발생시키며 보호함
                
            - base와 limit 레지스터를 활용한 메모리 보호 기법
                - base 레지스터: 메모리상의 프로세스 시작주소를 물리 주소로 저장
                - limit 레지스터: 프로세스의 사이즈(메모리 주소의 범위)를 저장
                - 프로세스의 접근 가능한 합법적인 메모리 영역 x (`base <= x < base+limit`) 밖에서 접근을 요구하면 trap 발생
                    
                    [https://camo.githubusercontent.com/d1cf6d562e863683d43c4a26178ad484458ac547185ee156734ac88de08a6fda/68747470733a2f2f696d67312e6461756d63646e2e6e65742f7468756d622f523132383078302f3f73636f64653d6d746973746f727926666e616d653d68747470732533412532462532466b2e6b616b616f63646e2e6e6574253246646e253246354c677574253246627471754e764b4d5277482532464a4f717a636d7a3877695866304b76376f6b66477a4b253246696d672e706e67](https://camo.githubusercontent.com/d1cf6d562e863683d43c4a26178ad484458ac547185ee156734ac88de08a6fda/68747470733a2f2f696d67312e6461756d63646e2e6e65742f7468756d622f523132383078302f3f73636f64653d6d746973746f727926666e616d653d68747470732533412532462532466b2e6b616b616f63646e2e6e6574253246646e253246354c677574253246627471754e764b4d5277482532464a4f717a636d7a3877695866304b76376f6b66477a4b253246696d672e706e67)
                    
                - 안전성을 위해 base와 limit 레지스터는 커널 모드에서만 수정 가능. (사용자 모드에서는 직접 변경 불가)
    - 논리 주소를 물리주소로 변환.
        - **가상주소**(한정된 메모리를 더 많이 이용하기 위해  사용)에서 실제 데이터가 담긴 곳에 접근 위해서 주소 변환 필요

---

## **메모리 과할당(over allocating)**

: 실제 메모리의 사이즈보다 더 큰 사이즈의 메모리를 프로세스에 할당한 상황

페이지 기법과 같은 메모리 관리 기법은 사용자가 눈치 못 채게 시스템 능률을 높이기 위해 눈속임을 통해 메모리 할당 → 가상 메모리 기법 이용

- 과할당 상황에 대해서 사용자를 속인 것을 들킬만한 상황이 존재
    1. 프로세스 실행 도중 페이지 폴트 발생
    2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음
    3. 메모리의 빈 프레임에 페이지를 올려야 하는데, 모든 메모리가 사용중이라 빈 프레임이 없음
- 과할당을 해결 위해 빈 프레임 확보해야:
    1. 메모리에 올라와 있는 한 프로세스를 종료시켜 빈 프레임을 얻음
        
        > 사용자에게 페이징 시스템을 들킬 위험 큼 → 하면 안 됨
        > 
    2. swapping 기법. 프로세스 하나를 swap out하고, 이 공간을 빈 프레임으로 활용
        
        > 페이지 교체
        > 

---

## **페이지 교체**

: 메모리 과할당이 발생했을 때, 프로세스 하나를 swap out해서 빈 프레임을 확보하는 것

1. 프로세스 실행 도중 페이지 부재 발생
2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 찾음
3. 메모리에 빈 프레임이 있는지 확인
    - 빈 프레임이 있으면 해당 프레임을 사용
    - 빈 프레임이 없으면, victim 프레임을 선정해 디스크에 기록하고 페이지 테이블을 업데이트함
4. 빈 프레임에 페이지 폴트가 발생한 페이지를 올리고, 페이지 테이블 업데이트

페이지 교체가 이루어지면 아무일이 없던것 처럼 프로세스를 계속 수행시켜주면서 사용자가 알지 못하도록 해야 함

이때, 아무일도 일어나지 않은 것처럼 하려면, 페이지 교체 당시 오버헤드를 최대한 줄여야 함

## **오버헤드를 감소시키는 해결법**

빈 프레임이 없는 상황에서 victim 프레임을 비울 때와 원하는 페이지를 프레임으로 올릴 때 두 번의 디스크 접근이 이루어짐

페이지 교체가 많이 이루어지면, 입출력 연산이 많이 발생하게 되면서 오버헤드 문제가 발생함

### **방법1**

클록 알고리즘

변경비트를 모든 페이지마다 둬서, victim 페이지가 정해지면 해당 페이지의 비트를 확인

해당 비트가 set 상태면? → 해당 페이지 내용이 디스크 상의 페이지 내용과 달라졌다는 뜻 (즉, 페이지가 메모리 올라온 이후 한번이라도 수정이 일어났던 것. 따라서 이건 디스크에 기록해야함)

bit가 clear 상태라면? → 디스크 상의 페이지 내용과 메모리 상의 페이지가 정확히 일치하는 상황 (즉, 디스크와 내용이 같아서 기록할 필요가 없음)

비트를 활용해 디스크에 기록하는 횟수를 줄이면서 오버헤드에 대한 수를 최대 절반으로 감소시키는 방법임

### **방법2**

페이지 교체 알고리즘을 상황에 따라 잘 선택해야 함

현재 상황에서 페이지 폴트를 발생할 확률을 최대한 줄여줄 수 있는 교체 알고리즘을 사용

FIFO

OPT

LRU

---

## **캐시 메모리**

: 주기억장치에 저장된 내용의 일부(자주 사용되는 것들)를 임시로 저장해두는 기억장치

CPU와 주기억장치의 속도 차이로 성능 저하를 방지하기 위한 방법

CPU가 이미 봤던걸 다시 재접근할 때, 메모리 참조 및 인출 과정에 대한 비용을 줄이기 위해 캐시에 저장해둔 데이터를 활용

캐시는 SRAM. → DRAM보다 빠름

## **CPU와 기억장치의 상호작용**

1. CPU에서 주소를 전달 → 캐시 기억장치에 명령이 존재하는지 확인
    1. (존재) Hit → 해당 명령어를 CPU로 전송 → 완료
    2. (비존재) Miss → 명령어를 갖고 주기억장치로 접근 → 해당 명령어를 가진 데이터 인출 → 해당 명령어 데이터를 캐시에 저장 → 해당 명령어를 CPU로 전송 → 완료
- CPU가 어떤 데이터를 원할지 어느정도 예측하고, 캐시에 필요한 정보가 들어있어야 성능이 높아짐
- 지역성의 원리 이용해 적중률 극대화 노력

## **지역성**

> 기억 장치 내의 정보를 균일하게 액세스 하는 것이 아니라 한 순간에 특정부분을 집중적으로 참조하는 특성
> 

**시간 지역성** : 최근에 참조된 주소의 내용은 곧 다음에도 참조되는 특성

**공간 지역성** : 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성

## **캐싱 라인**

빈번하게 사용되는 데이터들을 캐시에 저장했더라도, 필요한 데이터를 캐시에서 찾을 때 찾는 시간 줄이고 바로 접근해 출력할 수 있어야 캐시 활용이 의미있어짐

캐싱 라인: 캐시에 데이터 저장할 때, 자료구조를 활용해 묶어서 저장. 데이터의 메모리 주소를 저장한 태그 묶음. 

종류 - Direct Mapping, Full Associative Mapping, Set Associative Mapping

참고 링크 

- [https://rebro.kr/180?category=504670](https://rebro.kr/180?category=504670)
- [https://4legs-study.tistory.com/46](https://4legs-study.tistory.com/46)